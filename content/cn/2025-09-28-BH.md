---
title: BH控制定理
date: '2025-09-28'
categories:
  - 学习志
tags:
  - 珠海
  - 科研
slug: BH
show_toc: true
disable_comments: true
---

# 多重假设检验BH控制定理



## 1. 多重假设检验的设置

在 `$p$` 维多重假设检验中，结果可分为四类：

|                 | 接受 `$H_0 $`               | 拒绝 `$H_0$`                | 总计            |
| --------------- | -------------------------- | ------------------------- | --------------- |
| **`$ H_0$` 为真** | `$V$` (正确接受)             | `$U$` (错误发现，第I类错误) | `$p_0$`           |
| **`$H_0$` 为假**  | `$S$` (错误接受，第II类错误) | `$T$` (正确拒绝)            | `$p_1$`           |
| **总计**        | `$p - R$`                    | `$R$`                       | `$p = p_0 + p_1$` |

其中：
- `$U$` 表示第 I 类错误发现的总数 
- `$R$` 表示拒绝原假设的总数
- `$FDP = \frac{U}{\max\{R, 1\}}$`
- `$FDR = E[FDP] =  E\left[ \frac{U}{\max\{R, 1\}} \right]$`

## 2. 定理内容

### BH方法的FDR控制定理
对于给定的 `$FDR$` 控制水平 `$q \in (0,1)$`，如果多重检验的 `$p$` 值 `$\{ p_j \}_{j=1}^p$` 相互独立，则BH方法满足：
`$$
FDR = \frac{p_0}{p} q \leq q
$$`

## 3. 定理证明

**符号说明**：

- `$S_0 = \{ j : H_{0j} \text{为真} \}$`：正确原假设指标集

- `$ S_1 = S_0^c $`：错误原假设指标集

- `$ p_0 = |S_0| = \sum_i I_{i \in S_0} $`：正确原假设的总数


**分情况讨论**。

### 第一种情形（`$p_0 = 0$`）

当 `$p_0 = 0$` 时，正确原假设总数为 `$0$`，则 `$U = 0$`，`$FDR = E[\frac{U}{\max\{R, 1\}}] = 0$`，定理自然成立。

### 第二种情形（`$p_0 \geq 1$`）

#### 步骤1：定义和符号

令 `$U_i = I(\text{第 } i \text{ 个原假设被拒绝}) $`，则 `$ U = \sum_{i \in S_0} U_i $`，`$R = \sum_{i \in S_0 \cup S_1} U_i = \sum_{i = 1}^p U_i$`。按照 BH 流程，`$ U_i = I(p_i \ge \frac{k}{p} q)$`。相应地，`$FDP$` 和 `$FDR$` 可分别表示为：

`$$
FDP = \frac{U}{\max\{R, 1\}} = \sum_{i \in S_0} \frac{U_i}{\max\{R, 1\}}
$$`

`$$
FDR = E[FDP] = \sum_{i \in S_0} E\left[ \frac{U_i}{\max\{R, 1\}} \right]
$$`

#### 步骤2：处理`$ \frac{U_i}{\max\{R, 1\}} $`
在原假设成立时，`$p$` 值服从均匀分布 `$U(0,1)$`，因此对于任意 `$i \in S_0 $`，项 `$\frac{U_i}{\max\{R, 1\}}$` 服从同一分布。注意到 `$R$`为离散随机变量， 可进行离散化分解，得到点态等式：

`$$
\frac{U_i}{\max\{R, 1\}} = \sum_{k=1}^{p} \frac{U_i }{k}\cdot I\{R=k\} \tag{1}
$$`

该点态等式不仅仅是期望相等，更是**随机变量之间的等式**，它本质上是将随机变量`$\frac{U_i}{\max\{R, 1\}}$`分解为对 `$R$` 所有可能值的求和，这是一种常见的离散化技巧。

定义 `$R(p_i \to 0)$`：当第 `$i$` 个 `$p$` 值变为 `$0$` 时，即强制拒绝第 `$i$` 个假设，BH方法拒绝的假设总数。（BH方法是一个确定的算法：给定一组 `$p$` 值，它会产生确定的拒绝集合和拒绝数 `$R$`）。(1)式分两种情况考虑：

1. 如果 `$H_{0i}$` 被接受（`$U_i = 0$`）：`$U_i I\{R=k\} = U_i I\{R(p_i \to 0)=k\}$`；
2. 如果 `$H_{0i}$` 被拒绝（`$U_i = 1$`）：`$R = R(p_i \to 0)$`，`$U_iI\{ R=k\} = U_i I\{R(p_i \to 0)=k\}$`。

因此，(1)式可写为

`$$
\frac{U_i}{\max\{R, 1\}} = \sum_{k=1}^{p} \frac{U_i }{k} \cdot I\{R(p_i \to 0)=k\}, \quad i \in S_0 \tag{2}
$$`

#### 步骤3：条件期望 `$E\left[ \frac{U_i}{\max\{R, 1\}} \middle| \mathcal{F}_i \right] $`
定义 `$ \mathcal{F}_i $`​ 为 `$\{p_1, \cdots, p_{i-1}, p_{i+1}, \cdots, p_p\}$`​ 生成的σ-域。条件于 `$\mathcal{F}_i$` 意味着我们固定了所有其他 `$p$` 值的具体数值，只有第 `$i$` 个 `$p$` 值 `$p_i$` 仍然是随机的（在 `$H_0$` 成立下服从均匀分布）。
`$$
\begin{align*} 
E\left[ \frac{U_i}{\max\{R, 1\}} \middle| \mathcal{F}_i \right] \tag{3}
&= E\left[ \sum_{k=1}^{p} \frac{U_i I\{R(p_i \to 0)=k\}}{k} \middle| \mathcal{F}_i \right]\\ \tag{4}
&= \sum_{k=1}^{p} \frac{I\{R(p_i \to 0)=k\}}{k} E\left[ U_i \middle| \mathcal{F}_i \right]
\end{align*}
$$`


(4)成立是由于在 `$ \mathcal{F}_i $` 条件下，`$R(p_i \to 0)$` 是确定的，`$I\{R(p_i \to 0)=k\}$` 为常数，可提到期望符号外面。由于 `$p$` 值服从均匀分布且 `$p_i$` 与 `$\mathcal{F}_i$` 独立：

`$$
E\left[ U_i \middle| \mathcal{F}_i \right] = E\left[ I\{p_i \leq \frac{kq}{p}\} \middle| \mathcal{F}_i \right] = P \left(p_i \leq \frac{ R(p_i \to 0) q}{p} \middle| \mathcal{F}_i \right) = \frac{ R(p_i \to 0) q}{p} \tag{5}
$$`

将(5)代入(4)，得：
`$$
E\left[ \frac{U_i}{\max\{R, 1\}} \middle| \mathcal{F}_i \right] = \sum_{k=1}^{p} \frac{I\{R(p_i \to 0)=k\}}{k} \cdot \frac{ R(p_i \to 0) q}{p} = \frac{q}{p} \sum_{k=1}^{p} I\{R(p_i \to 0)=k\} = \frac{q}{p}
$$`

#### 步骤4：无条件期望`$E\left[ \frac{U_i}{\max\{R, 1\}}  \right] $`
由条件期望的迭代律：
`$$
E\left[ \frac{U_i}{\max\{R, 1\}} \right] = E\left[ E\left[ \frac{U_i}{\max\{R, 1\}} \middle|\mathcal{F}_i \right] \right] = \frac{q}{p}
$$`

因此：
`$$
FDR = \sum_{i \in S_0} E\left[ \frac{U_i}{\max\{R, 1\}} \right] = p_0 \cdot \frac{q}{p} = \frac{p_0}{p} q \leq q
$$`

**证毕**。

## 补充解释

### 1.为什么在原假设成立时，`$p$` 值服从均匀分布 `$U(0,1)$`？

在假设检验中，`$p$` 值定义为：在原假设 `$H_0$` 成立的条件下，观察到检验统计量至少与实际观测值一样极端的概率。

数学上，如果 `$T$` 是检验统计量，`$t_{obs}$` 是实际观测值，则：
`$$ p = P(T \geq t_{obs} | H_0) \quad \text{(对于单侧检验)} $$`

**关键点**：

- 当 `$ H_0 $` 成立且 `$T$` 的分布是连续时，`$T$` 的累积分布函数（CDF）记为 `$F(t)$`
- 根据概率积分变换定理，随机变量 `$F(T)$` 服从均匀分布 `$U(0,1)$`
- 由于 `$p = 1 - F(t_{obs})$`（对于右侧检验），而 `$F(t_{obs})$` 是均匀分布的，因此 `$p$` 也服从均匀分布 `$U(0,1)$`

### 2. 为什么对于任意 `$ i \in S_0 $`，项 `$U_i/\max\{R, 1\}$` 服从同一分布？

**同分布性的原因**：

对于所有 `$ i \in S_0 $`（即所有真实原假设），项 `$\frac{U_i}{\max\{R, 1\}}$` 服从同一分布，主要原因如下：

1. **`$p$` 值的独立同分布性**：
   - 所有正确原假设的`$p$` 值 `$ \{p_i\}_{i \in S_0} $` 是相互独立的
   - 每个 `$p_i$` 都服从相同的均匀分布 `$U(0,1)$`
   - 因此，这些 `$p$` 值是独立同分布的（i.i.d.）

2. **BH方法的对称性**：
   - BH方法基于排序的p 值做出决策：`$p_{(1)} \leq p_{(2)} \leq \cdots \leq p_{(p)}$`
   - 由于`$p$` 值是交换的（exchangeable），BH方法对每个真实原假设的处理是对称的
   - 任何两个真实原假设 `$i$` 和 `$j$` 在统计上是不可区分的

3. **联合分布的对称性**：
   - 随机向量 `$(U_i, R)$` 的联合分布对于所有 `$ i \in S_0 $` 是相同的
   - 因此，函数 `$\frac{U_i}{\max\{R, 1\}}$` 的分布也不依赖于具体的 `$i$`

### 3. 项 `$U_i/\max\{R, 1\}$` 服从什么分布

项 `$\frac{U_i}{\max\{R, 1\}}$` **取值范围**为离散集合：`$\{0\} \cup \left\{\frac{1}{k} : k = 1, 2, \ldots, p\right\}$`​，服从**离散混合分布**，**概率质量函数**为：
`$$
P\left(\frac{U_i}{\max\{R, 1\}} = x\right) = 
\begin{cases}
P(U_i = 0) & \text{若 } x = 0 \\
P(U_i = 1, R = k) & \text{若 } x = \frac{1}{k}, k = 1, \ldots, p
\end{cases}
$$`

|  `$\frac{U_i}{\max\{R, 1\}}$`    |   `$0$`   |   `$1$`   | `$\cdots$` | `$\frac{1}{p}$` |
| ---- | :--: | ---- | ---- |  ---- |
| 取值概率 | `$P(U_i = 0)$` | `$P(U_i = 1 \cap R = 1)$` | `$\cdots$` | `$P(U_i = 1 \cap R = p)$` |

其**期望值**：
`$$
E\left[\frac{U_i}{\max\{R, 1\}}\right] = 0 \cdot P(U_i = 0) + \sum_{k=1}^{p} \frac{1}{k} \cdot P(U_i = 1, R = k) = \sum_{k=1}^{p} \frac{1}{k} E[U_i I\{R = k\}]
$$`

但这样求不出，而是利用条件期望和点态公式`$\frac{U_i}{\max\{R, 1\}} = \sum_{k=1}^{p} \frac{U_i }{k} \cdot I\{R=k\}$`：
`$$
E\left[\frac{U_i}{\max\{R, 1\}}\right] = E \left\{ E\left[\frac{U_i}{\max\{R, 1\}} \middle|  \mathcal{F}_i\right] \right\}= E \left\{   E \left[ \sum_{k=1}^{p} \frac{U_i}{k} \cdot I \{R = k\} \middle|  \mathcal{F}_i \right] \right\}
$$`



### 4. 为什么在 `$\mathcal{F}_i$` 条件下 `$R(p_i \to 0)$` 是确定的？

在给定 `$\mathcal{F}_i$` 的条件下：

1. **所有其他 `$p$` 值被固定**：`$\mathcal{F}_i$` 包含了除 `$p_i$` 外所有 `$p$` 值的具体数值
2. **`$p_i$` 被明确设为`$0$`**：在计算 `$R(p_i \to 0)$` 时，我们明确将 `$p_i$` 设置为`$0$`
3. **BH算法的确定性**：由于所有输入（`$p$` 值）都是确定的（其他 `$p$` 值固定，`$p_i$` 设为`$0$`），BH算法的输出 `$R(p_i \to 0)$` 也是确定的

因此，在给定 `$\mathcal{F}_i$` 的条件下，`$R(p_i \to 0)$` 是一个**确定的数值**，而不是随机变量。



### 5. 为什么 `$I\{R(p_i \to 0)=k\}$` 是常数？

由于在 `$\mathcal{F}_i$` 条件下 `$R(p_i \to 0)$` 是确定的：
- `$R(p_i \to 0)$` 有某个具体的数值，比如 `$k_0$`
- 对于每个 `$k$`，事件 `$\{R(p_i \to 0) = k\}$` 要么成立（如果 `$k = k_0$`），要么不成立（如果 `$k \neq k_0$`）
- 因此，指示函数 `$I\{R(p_i \to 0) = k\}$` 在给定 `$\mathcal{F}_i$` 下是常数：
  - 如果 `$k = k_0$`，则 `$I\{R(p_i \to 0) = k\} = 1$`（常数）
  - 如果 `$k \neq k_0$`，则 `$I\{R(p_i \to 0) = k\} = 0$`（常数）

