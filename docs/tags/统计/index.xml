<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>统计 on Tan Jay | 唐 洁</title>
    <link>//localhost:1313/tags/%E7%BB%9F%E8%AE%A1/</link>
    <description>Recent content in 统计 on Tan Jay | 唐 洁</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 17 Oct 2022 00:00:00 +0000</lastBuildDate>
    <atom:link href="//localhost:1313/tags/%E7%BB%9F%E8%AE%A1/" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>大脑突然就宕机了</title>
      <link>//localhost:1313/cn/2022/10/17/note/</link>
      <pubDate>Mon, 17 Oct 2022 00:00:00 +0000</pubDate>
      <author>Tan Jay</author>
      <guid>//localhost:1313/cn/2022/10/17/note/</guid>
      <description>
        <![CDATA[
        <p>看论文看着看着，看见“半参数模型”几个字，愣了一下，我竟然对这个朝夕相伴这么久的名词，还不知道究竟是个啥，自己研究的模型到底算不算半参数模型？头晕😵‍💫～</p>
<p>上网搜一搜，大家给的答案：</p>
<ul>
<li><a href="https://www.jianshu.com/p/a97c5a0718f8">半参数模型</a></li>
<li><a href="https://blog.sciencenet.cn/blog-941132-1080151.html">杨立坚写的统计学科普</a></li>
<li><a href="https://www.zhihu.com/question/24373415">如何理解统计学半参数的概念？</a></li>
</ul>
<p>选择一个答案记录一下，</p>
<p>参数回归是事先假定模型的形式，然后用数据去估计这个模型的系数。而非参数回归则是不假定模型形式，直接从数据来拟合模型。参数回归最基本的是线性模型，非参数回归最简单的最近邻方法。而半参数回归则是，模型中有一部分的结构是已知的，需要估计参数，而另外一部分结构未知。</p>
<p>比如有<code>$X_1$</code>与<code>$X_2$</code>两个自变量，<code>$Y$</code>为因变量，我们可以对回归函数建模为：</p>
<p>$$E[Y|X_1, X_2]= \alpha + \beta X_1 + h(X_2)$$</p>
<p>那么，对<code>$h(X_2)$</code>的分析就是非参的，而对<code>$X_1$</code>的分析为参数的。但如果将其视作整体，其实整个模型严格意义上还是非参的。</p>

        
        ]]>
      </description>
    </item>
    
    
    
    <item>
      <title>Borel-Cantelli引理</title>
      <link>//localhost:1313/cn/2022/09/03/borel-cantelli/</link>
      <pubDate>Sat, 03 Sep 2022 00:00:00 +0000</pubDate>
      <author>Tan Jay</author>
      <guid>//localhost:1313/cn/2022/09/03/borel-cantelli/</guid>
      <description>
        <![CDATA[
        <p>这是一篇摘记<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>。</p>
<h2 id="引理作用">引理作用</h2>
<p>Borel-Cantelli引理是概率论中一个很重要的引理。该引理可以帮忙我们理解<strong>几乎处处收敛</strong>和<strong>依概率收敛</strong>之间的关系，也可用于论证强相合性和强大数律等。为说明该引理，法国数学家博雷尔(Émile Borel, 1871-1956)在1913年介绍了“打字的猴子”的概念。无限猴子定理指出，一个在打字机键盘上随机敲打键盘的猴子，只要时间无限长，那么它几乎肯定会键入任何给定的文本，例如莎士比亚全集。</p>
<h2 id="引理由来">引理由来</h2>
<p><strong>定义1</strong> <code>$\quad$</code> 设<code>$\{X_n,n \ge 1\}$</code> 是随机变量序列，若存在随机变量<code>$X$</code>使得
$$Pr\left(\omega \in \Omega: \lim_{n \to \infty} X_n(\omega)=X(\omega)\right)=1,$$
则称随机变量序列<code>$\{X_n,n \ge 1\}$</code>几乎必然收敛（或以概率1收敛）于<code>$X$</code>，记为<code>$X_n \to X, a.s.$</code>。</p>
<p><strong>定义2</strong> <code>$\quad$</code> 设<code>$\{X_n,n \ge 1\}$</code> 是随机变量序列，若存在随机变量<code>$X$</code>使得对任意的<code>$\epsilon &gt; 0$</code>，有
$$\lim_{n \to \infty} Pr(|X_n-X|\ge\epsilon)=0,$$
则称随机变量序列<code>$\{X_n,n \ge 1\}$</code>依概率收敛于<code>$X$</code>， 记为<code>$X_n \stackrel{p}{\longrightarrow} X$</code>。</p>
<p><strong>定理1</strong> <code>$\quad$</code> <code>$X_n \implies X, a.s.$</code> 等价于<code>$\forall \epsilon &gt; 0$</code>，
$$Pr(|X_n-X|&gt;\epsilon \ i.o.) = \lim_{n \to \infty}Pr(\bigcup_{k=n}^{\infty}|X_n-X|&gt;\epsilon)=0。$$</p>
<p><strong>总结</strong> <code>$\quad$</code> 几乎处处收敛考察的是不收敛的样本点的概率是否为 0，而依概率收敛则考察<code>$X_n$</code>和<code>$X$</code>差异的尾概率是否趋于 0。定理1给出几乎处处收敛的等价定义，可知，几乎处处收敛<code>$\implies$</code>依概率收敛。那么在什么条件下，依概率收敛<code>$\implies$</code>几乎处处收敛呢？对此，Borel-Cantelli第一引理给出了答案。</p>
<h2 id="引理内容">引理内容</h2>
<p><strong>引理1</strong> <code>$\quad$</code> 设<code>$\{A_n, n=1,2,\cdots\}$</code>是一列事件，若<code>$\sum_{n=1}^{\infty}Pr(A_n)&lt;\infty$</code>，则<code>$Pr(A_n,i.o)=0 $</code>。</p>
<p>令<code>$A_n=\{|X_n-X|&gt;\epsilon\}$</code>，则可知依概率收敛仅要求级数的每一项<code>$Pr(A_n)$</code>趋于0。而几乎处处收敛要求更高一点，需要对应的级数是收敛的(充分条件)，这就要求级数的每一项<code>$Pr(A_n)$</code>趋于0的速度要快一点。</p>
<p><strong>引理1推论</strong> <code>$\quad$</code> 依概率收敛可以推出子列几乎处处收敛。</p>
<p><strong>引理2</strong> <code>$\quad$</code> 设<code>$\{A_n, n=1,2,\cdots\}$</code>是独立的事件列，若<code>$\sum_{n=1}^{\infty}Pr(A_n)=\infty$</code>，则<code>$Pr(A_n,i.o)=1 $</code>。</p>
<p>下面给出一个简单的例子予以说明引理2。假设我们抛掷一个骰子无穷多次，那么骰子正面出现数值6无穷多次的概率是多少？答案是1。实际上令<code>$A_n$</code>表示第<code>$n$</code>次抛掷出现6，容易知道<code>$Pr(A_n)=1/6$</code>，而且<code>$\{A_n,\ge 1\}$</code>之间相互独立，从而<code>$\sum_{n=1}^{\infty}Pr(A_n)=\sum_{n=1}^{\infty}1/6=\infty$</code>，因此，<code>$A_n$</code>发生无穷多次的概率是1。换而言之，只要某一事件可能发生，即使发生的概率非常非常小，同时不同事件相互独立，则该事件在无限长时间内几乎必然发生。</p>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>公众号：<em>郭老师统计小课堂</em>。 <a href="https://mp.weixin.qq.com/s/XyfP9-ZTr_rb9CufIwkCDA">Borel-Cantelli引理</a>&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>

        
        ]]>
      </description>
    </item>
    
    
  </channel>
</rss>
