<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>论文 on Tan Jay | 唐 洁</title>
    <link>/tags/%E8%AE%BA%E6%96%87/</link>
    <description>Recent content in 论文 on Tan Jay | 唐 洁</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 02 Aug 2024 00:00:00 +0000</lastBuildDate>
    <atom:link href="/tags/%E8%AE%BA%E6%96%87/" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>OOD学习</title>
      <link>/cn/2024/08/02/ood/</link>
      <pubDate>Fri, 02 Aug 2024 00:00:00 +0000</pubDate>
      <author>Tan Jay</author>
      <guid>/cn/2024/08/02/ood/</guid>
      <description>
        <![CDATA[
        <h2 id="sharon-li">Sharon Li</h2>
<table>
<thead>
<tr>
<th>网页</th>
<th style="text-align:left">链接</th>
</tr>
</thead>
<tbody>
<tr>
<td>主页</td>
<td style="text-align:left"><a href="https://pages.cs.wisc.edu/~sharonli/index.html">Sharon Li - UW Madison Computer Sciences</a></td>
</tr>
<tr>
<td>代码</td>
<td style="text-align:left"><a href="https://github.com/deeplearning-wisc/knn-ood">deeplearning-wisc/knn-ood: Code for ICML 2022 paper &ldquo;Out-of-distribution Detection with Deep Nearest Neighbors&rdquo;</a></td>
</tr>
<tr>
<td>github</td>
<td style="text-align:left"><a href="https://github.com/yixuanli">YixuanLi (Sharon Y. Li)</a></td>
</tr>
</tbody>
</table>

        
        ]]>
      </description>
    </item>
    
    
    
    <item>
      <title>专家</title>
      <link>/cn/2023/08/15/dr/</link>
      <pubDate>Tue, 15 Aug 2023 00:00:00 +0000</pubDate>
      <author>Tan Jay</author>
      <guid>/cn/2023/08/15/dr/</guid>
      <description>
        <![CDATA[
        <h3 id="王建军-http-math-swu-edu-cn-info-1019-2612-htm"><a href="http://math.swu.edu.cn/info/1019/2612.htm">王建军</a></h3>
<h3 id="张师超-http-www-globalauthorid-com-webportal-authorview-wd-gaid10125982-rc-37037a"><a href="http://www.globalauthorid.com/WebPortal/AuthorView?wd=GAID10125982&amp;rc=37037A">张师超</a></h3>
<h3 id="朱晓峰-http-www-globalauthorid-com-webportal-authorview-wd-gaid10127811-rc-013f3e"><a href="http://www.globalauthorid.com/WebPortal/AuthorView?wd=GAID10127811&amp;rc=013F3E">朱晓峰</a></h3>
<ul>
<li><a href="/papers/QinRecom/ZhuXF-1.pdf">论文1</a></li>
<li><a href="/papers/QinRecom/ZhuXF-2.pdf">论文2</a></li>
</ul>

        
        ]]>
      </description>
    </item>
    
    
    
    <item>
      <title>李红权</title>
      <link>/cn/2023/08/15/dr.li/</link>
      <pubDate>Tue, 15 Aug 2023 00:00:00 +0000</pubDate>
      <author>Tan Jay</author>
      <guid>/cn/2023/08/15/dr.li/</guid>
      <description>
        <![CDATA[
        <h2 id="李红权-https-sxy-hunnu-edu-cn-info-1054-2670-htm"><a href="https://sxy.hunnu.edu.cn/info/1054/2670.htm">李红权</a></h2>
<h3 id="英文">英文</h3>
<ol>
<li><strong>Hongquan Li</strong>, Zhihong Yi. <a href="https://sci-hub.st/downloads/2019-11-24/5d/li2019.pdf#navpanes=0&amp;view=FitH">Portfolio selection with coherent investor’s expectations under uncertainty</a> [J]. <em>Expert Systems With Applications</em>, 2019, 133:49-58.</li>
<li><strong>Hongquan Li</strong>, Zhihong Yi, Yong Fang. <a href="https://sci-hub.st/tree/0a/19/0a19e4f23dfba0ea77c73f6ace589230.pdf#navpanes=0&amp;view=FitH">Portfolio selection under uncertainty by the ordered modular average operator</a> [J]. <em>Fuzzy Optimization and Decision Making</em>, 2019, 18(1): 1-14.</li>
<li>Zhihong Yi, <strong>Hongquan Li</strong>. <a href="https://sci-hub.ru/10.1002/int.21974">Triangular norm-based cuts and possibility characteristics of triangular intuitionistic fuzzy numbers for decision making</a> [J]. <em>International Journal of Intelligent Systems</em>, 2018, 33(6): 1165–1179.</li>
<li><strong>Hongquan Li</strong>, et al. <a href="https://zero.sci-hub.st/5506/7f100299f2c2e364f779afd2b0474a40/li2015.pdf#navpanes=0&amp;view=FitH">Transaction Tax, Heterogeneous Traders and Market Volatility</a> [J]. <em>Kybernetes</em>, 2015, 44(5): 757-770.</li>
<li><strong>Hongquan Li</strong>, Yongmiao Hong. <a href="https://moscow.sci-hub.st/1658/c8a407e2358c0bc49ef87c1933eaafcf/li2011.pdf#navpanes=0&amp;view=FitH">Financial volatility forecasting with range-based autoregressive volatility model</a> [J]. <em>Finance Research Letters</em>, 2011, 8(2): 69-76.</li>
</ol>
<h3 id="中文-https-kns-cnki-net-kcms2-author-detail-v-3uoqihg8c45ugik-loaz12zkvhzevn-porli7erqakr1r6sf3d14tubesnp2omfmjnx5nfxpfimmgpjx90xaizdprblnkwb32w-b9ewkupsqyp3-c-cp-imyathjifqu-uniplatform-nzkpt"><a href="https://kns.cnki.net/kcms2/author/detail?v=3uoqIhG8C45UgIk_lOaz12Zkvhzevn-PORLI7ErqaKr1r6Sf3d14tUbeSNP2OmFmJNX5NFXpFIMmgPJX90xaIZdprBLNkWb32W_b9EwkUPsqYP3-C-cp_ImYathjifqu&amp;uniplatform=NZKPT">中文</a></h3>
<ol>
<li><strong>李红权</strong>, 何敏园, 黄莹莹. 我国金融机构的系统重要性评估: 基于多元极值理论[J]. <em>中国管理科学</em>, 2020.</li>
<li><strong>李红权</strong>, 曹佩文. CEO年龄与公司风险承担行为[J].<em>湖南师范大学社会科学学报</em>, 2020.</li>
<li><strong>李红权</strong>, 何敏园, 周亮. 人民币在岸市场的国际影响力研究: 基于修正的溢出指数模型[J]. <em>系统工程理论与实践</em>, 2020.</li>
<li><strong>李红权</strong>, 何敏园, 严定容. 国际金融风险传导的微观经济基础研究: 基于公司数据角度[J]. <em>金融评论</em>, 2017.</li>
<li><strong>李红权</strong>, 洪永淼, 汪寿阳. 我国A股市场与美股、港股的互动关系研究: 基于信息溢出视角[J]. <em>经济研究</em>, 2011.</li>
</ol>

        
        ]]>
      </description>
    </item>
    
    
    
    <item>
      <title>蔡宗武</title>
      <link>/cn/2023/08/15/dr.zong/</link>
      <pubDate>Tue, 15 Aug 2023 00:00:00 +0000</pubDate>
      <author>Tan Jay</author>
      <guid>/cn/2023/08/15/dr.zong/</guid>
      <description>
        <![CDATA[
        <h2 id="蔡宗武">蔡宗武</h2>
<p>蔡宗武教授(Prof.Zongwu Cai)，美国堪萨斯大学经济系经济学教授，计量经济学Charles  Oswald教授，美国统计协会会员，美国经济协会会员，国际数理统计协会会员，泛华统计协会会员。主要研究领域为计量经济学、风险管理、数据分析建模、非线性和非平稳时间序列及其应用等。目前已在经济学、统计学以及金融学等期刊上发表论文110余篇，其中包括Econometric Theory、Journal of Econometrics和Journal of the American Statistical Association等计量经济学和统计学国际顶级期刊。担任过“中国留美经济学会”会长和Econometric Reviews、Econometric Theory和Journal of Business and Economic Statistics等期刊的副主编。</p>
<h3 id="英文-https-so1-cljtscd-com-citations-hl-zh-cn-user-ohpedjyaaaaj-view-op-list-works-sortby-pubdate"><a href="https://so1.cljtscd.com/citations?hl=zh-CN&amp;user=oHPEDJYAAAAJ&amp;view_op=list_works&amp;sortby=pubdate">英文</a></h3>
<h3 id="中文-https-kns-cnki-net-kcms2-author-detail-v-3uoqihg8c45ugik-loaz1zw8mvx0u3dz1t6v0wdoqcybnm4o5adardhga3jx70duojkl2bt3jcjsykfbfcy3pzav-onxbfgy3j-r5mawwg1qddcrgtlok3uxeitbfvkp-uniplatform-nzkpt"><a href="https://kns.cnki.net/kcms2/author/detail?v=3uoqIhG8C45UgIk_lOaz1zw8MVX0u3dz1t6v0WdOQCybnm4o5aDarDHga3JX70DuojKL2bT3JcJsykfbFCy3PZav-OnxbFGy3J_R5MAwWg1QDDCRGTlOK3UxeITBfvKp&amp;uniplatform=NZKPT">中文</a></h3>
<ul>
<li>2022-10-15 <a href="https://kns.cnki.net/kns8/Detail?sfield=fn&amp;QueryID=29&amp;CurRec=1&amp;recid=&amp;FileName=JLJX202204001&amp;DbName=CJFDLAST2022&amp;DbCode=CJFD&amp;yx=&amp;pr=&amp;URLID=">宏观审慎与金融稳定：基于计量经济政策评估方法的研究</a></li>
<li>2022-04-20 <a href="https://kns.cnki.net/kns8/Detail?sfield=fn&amp;QueryID=29&amp;CurRec=2&amp;recid=&amp;FileName=JJYJ202204010&amp;DbName=CJFDLAST2022&amp;DbCode=CJFD&amp;yx=&amp;pr=&amp;URLID=">货币政策和宏观审慎政策双支柱调控框架效应研究</a></li>
<li>2021-10-15 <a href="https://kns.cnki.net/kns8/Detail?sfield=fn&amp;QueryID=29&amp;CurRec=3&amp;recid=&amp;FileName=JLJX202104002&amp;DbName=CJFDLAST2021&amp;DbCode=CJFD&amp;yx=&amp;pr=&amp;URLID=">部分条件分位数处理效应的估计</a></li>
<li>2021-04-15 <a href="https://kns.cnki.net/kns8/Detail?sfield=fn&amp;QueryID=29&amp;CurRec=4&amp;recid=&amp;FileName=JLJX202102001&amp;DbName=CJFDLAST2022&amp;DbCode=CJFD&amp;yx=&amp;pr=&amp;URLID=">基于面板数据的处置效应估计的计量方法最新进展</a></li>
<li>2020-10-22 <a href="https://kns.cnki.net/kns8/Detail?sfield=fn&amp;QueryID=29&amp;CurRec=5&amp;recid=&amp;FileName=XTLL202110014&amp;DbName=CJFDLAST2021&amp;DbCode=CJFD&amp;yx=A&amp;pr=&amp;URLID=11.2267.N.20201022.1343.008">带有变量选择的协变量平衡倾向得分的估计：基于GMM-LASSO方法</a></li>
<li>2020-09-23 <a href="https://kns.cnki.net/kns8/Detail?sfield=fn&amp;QueryID=29&amp;CurRec=6&amp;recid=&amp;FileName=XTLL202107003&amp;DbName=CJFDLAST2021&amp;DbCode=CJFD&amp;yx=A&amp;pr=&amp;URLID=11.2267.n.20200922.1715.004">企业风险信息披露与债券风险溢价——基于债券募集说明书的文本分析</a></li>
<li>2020-04-25 <a href="https://kns.cnki.net/kns8/Detail?sfield=fn&amp;QueryID=29&amp;CurRec=7&amp;recid=&amp;FileName=XTLL202004001&amp;DbName=CJFDLAST2020&amp;DbCode=CJFD&amp;yx=&amp;pr=&amp;URLID=">信息获利、道德风险与询价机构报价</a></li>
<li>2019-04-25 <a href="https://kns.cnki.net/kns8/Detail?sfield=fn&amp;QueryID=29&amp;CurRec=8&amp;recid=&amp;FileName=XTLL201904008&amp;DbName=CJFDLAST2019&amp;DbCode=CJFD&amp;yx=&amp;pr=&amp;URLID=">企业社会责任对现金持有价值的影响——基于分位数回归模型的研究</a></li>
<li>2018-10-31 <a href="https://kns.cnki.net/kns8/Detail?sfield=fn&amp;QueryID=29&amp;CurRec=9&amp;recid=&amp;FileName=ZWGD201810001&amp;DbName=CJFDLAST2018&amp;DbCode=CJFD&amp;yx=&amp;pr=&amp;URLID=">创新、内生增长与气候变化：2018年度诺贝尔经济科学奖得主的贡献简评</a></li>
<li>2017-06-15 <a href="https://kns.cnki.net/kns8/Detail?sfield=fn&amp;QueryID=29&amp;CurRec=10&amp;recid=&amp;FileName=XTGC201703006&amp;DbName=CJFDLAST2017&amp;DbCode=CJFD&amp;yx=&amp;pr=&amp;URLID=">企业盈余管理与流动性风险</a></li>
<li>2012-04-15 <a href="https://kns.cnki.net/kns8/Detail?sfield=fn&amp;QueryID=29&amp;CurRec=11&amp;recid=&amp;FileName=XTLL201204003&amp;DbName=CJFD2012&amp;DbCode=CJFD&amp;yx=&amp;pr=&amp;URLID=">人民币汇率的半参数预测模型</a></li>
<li>2010-01-15 <a href="https://kns.cnki.net/kns8/Detail?sfield=fn&amp;QueryID=29&amp;CurRec=12&amp;recid=&amp;FileName=XTLL201001004&amp;DbName=CJFD2010&amp;DbCode=CJFD&amp;yx=&amp;pr=&amp;URLID=">中国股市权证定价的带均值回归跳跃扩散模型</a></li>
<li>2009-05-28 <a href="https://kns.cnki.net/kns8/Detail?sfield=fn&amp;QueryID=29&amp;CurRec=13&amp;recid=&amp;FileName=XMDS200903006&amp;DbName=CJFD2009&amp;DbCode=CJFD&amp;yx=&amp;pr=&amp;URLID=">最小下偏矩套期保值比率估计研究——基于混合copula方法</a></li>
</ul>

        
        ]]>
      </description>
    </item>
    
    
    
    <item>
      <title>NBEL</title>
      <link>/cn/2022/12/02/nbel/</link>
      <pubDate>Fri, 02 Dec 2022 00:00:00 +0000</pubDate>
      <author>Tan Jay</author>
      <guid>/cn/2022/12/02/nbel/</guid>
      <description>
        <![CDATA[
        <ul>
<li>
<p>曾力立. <a href="/papers/HigDimen/%E6%9B%BE%E5%8A%9B%E7%AB%8B.pdf"><code>高维线性回归模型下的经验似然</code></a></p>
</li>
<li>
<p><a href="https://xueshu.zidianzhan.net/citations?user=b3XlCawAAAAJ&amp;hl=zh-CN&amp;oi=sra">彭亮</a>. <a href="/papers/NBEL/PengL-2014-1.pdf"><code>高维线性模型经验似然检验</code></a> <a href="/papers/NBEL/PengL-2014-1-note.pdf">✓</a></p>
<ul>
<li>
<p><a href="/papers/NBEL/PengL-2014-2.pdf"><code>高维线性模型经验似然检验</code></a></p>
</li>
<li>
<p><a href="/papers/NBEL/WangR-2013.pdf"><code>Jacknife经验似然比检验两个高维均值是否相等问题</code></a></p>
</li>
</ul>
</li>
<li>
<p>Kitamura. <a href="/papers/NBEL/Kitamura-1997.pdf"><code>经验似然方法及弱相依过程</code></a> <a href="/papers/NBEL/Kitamura-1997-note.pdf">✓</a></p>
</li>
<li>
<p><a href="https://xs2.zidianzhan.net/citations?user=lZUH1lcAAAAJ&amp;hl=zh-CN&amp;oi=sra">汤琤咏</a>，冷琛雷. <a href="/papers/HigDimen/TangCY-2010.pdf"><code>高维惩罚经验似然</code></a> <a href="/papers/HigDimen/TangCY-2010-note.pdf">✓</a></p>
</li>
<li>
<p><a href="https://xs2.zidianzhan.net/citations?user=rsT2stMAAAAJ&amp;hl=zh-CN&amp;oi=sra">冷琛雷</a>，汤琤咏. <a href="/papers/HigDimen/LengCL-2012.pdf"><code>惩罚经验似然与高维估计方程</code></a> <a href="/papers/HigDimen/LengCL-2012-note.pdf">✓</a></p>
</li>
</ul>

        
        ]]>
      </description>
    </item>
    
    
    
    <item>
      <title>知识版图扩建</title>
      <link>/cn/2022/11/29/xuwangli/</link>
      <pubDate>Tue, 29 Nov 2022 00:00:00 +0000</pubDate>
      <author>Tan Jay</author>
      <guid>/cn/2022/11/29/xuwangli/</guid>
      <description>
        <![CDATA[
        <h2 id="课外拓展">课外拓展</h2>
<ul>
<li>
<p>卢一强. <a href="/papers/XuWangli/%E5%8D%A2%E4%B8%80%E5%BC%BA.pdf"><code>变系数混合模型的光滑样条推断</code></a></p>
</li>
<li>
<p>李再兴. <a href="/papers/XuWangli/%E6%9D%8E%E5%86%8D%E5%85%B4.pdf"><code>大学课程第一堂课的教学探讨——以《数理统计》为例</code></a></p>
</li>
<li>
<p>何胜美. <a href="/papers/XuWangli/%E4%BD%95%E8%83%9C%E7%BE%8E.pdf"><code>基于秩能量距离的超高维特征筛选研究</code></a></p>
</li>
<li>
<p>陈松灿. <a href="/papers/XuWangli/%E9%99%88%E6%9D%BE%E7%81%BF.pdf"><code>基于随机投影的高维数据流聚类</code></a></p>
</li>
<li>
<p>崔甲蓉. <a href="/papers/XuWangli/%E5%B4%94%E7%94%B2%E8%93%89-2019.pdf"><code>改进的基于图方法对真实原假设比例的估计</code></a></p>
</li>
<li>
<p>崔甲蓉. <a href="/papers/XuWangli/%E5%B4%94%E7%94%B2%E8%93%89-2020.pdf"><code>基于经验分布函数的高维正态性检验</code></a></p>
</li>
<li>
<p>石磊. <a href="/papers/XuWangli/%E7%9F%B3%E7%A3%8A.pdf"><code>物种间不确定性相互关系分析一种基于非参数估计的变系数模型</code></a></p>
</li>
<li>
<p>金立斌. <a href="/papers/XuWangli/%E9%87%91%E7%AB%8B%E6%96%8C.pdf"><code>偏正态混合模型的惩罚极大似然估计</code></a></p>
</li>
<li>
<p>张军舰. <a href="/papers/XuWangli/%E5%BC%A0%E5%86%9B%E8%88%B0.pdf"><code>非参数似然方法及其应用研究进展</code></a></p>
</li>
<li>
<p>邱涛. <a href="/papers/XuWangli/%E9%82%B1%E6%B6%9B.pdf"><code>高维两样本位置参数秩和检验</code></a> <a href="/papers/XuWangli/%E9%82%B1%E6%B6%9B-note.pdf">✓</a></p>
</li>
<li>
<p>朱利平. <a href="/papers/XuWangli/%E6%9C%B1%E5%88%A9%E5%B9%B3.pdf"><code>含发散维数自变量的单指标模型中方向向量的稳健估计</code></a></p>
</li>
<li>
<p>许王莉. <a href="/papers/XuWangli/XuWL-2009-1.pdf"><code>双向分类随机效应模型中方差分量的估计</code></a></p>
</li>
<li>
<p>许王莉. <a href="/papers/XuWangli/XuWL-2009-2.pdf"><code>线性混合效应模型中方差分量的估计</code></a></p>
</li>
<li>
<p>许王莉. <a href="/papers/XuWangli/XuWL-2012.pdf"><code>线性混合模型方差分量的谱分解估计</code></a></p>
</li>
<li>
<p>许王莉. <a href="/papers/XuWangli/XuWL-2007.pdf"><code>对部分线性模型用惩罚最小二乘最优光滑化的注记</code></a></p>
</li>
<li>
<p>许王莉. <a href="/papers/XuWangli/XuWL-2022.pdf"><code>一个高维两样本均值检验问题</code></a></p>
</li>
</ul>
<blockquote>
<p>其中提到文献有，</p>
</blockquote>
<blockquote>
<p>白志东. <a href="/papers/XuWangli/BaiZD-1996.pdf"><code>以两样本均值问题为例说明高维影响</code></a></p>
</blockquote>
<blockquote>
<p>陈松溪. <a href="/papers/XuWangli/ChenSX-2010.pdf"><code>高维两样本检验应用于基因组测试</code></a></p>
</blockquote>

        
        ]]>
      </description>
    </item>
    
    
    
    <item>
      <title>高维在读论文</title>
      <link>/cn/2022/11/29/higdimen/</link>
      <pubDate>Tue, 29 Nov 2022 00:00:00 +0000</pubDate>
      <author>Tan Jay</author>
      <guid>/cn/2022/11/29/higdimen/</guid>
      <description>
        <![CDATA[
        <!-- <font style="background-color: #FFFFCD;">[`PDF`](/papers/HigDimen/2.pdf)</font>
<font style="background-color: #F0FFFF;">[✓](/papers/HigDimen/2-note.pdf)</font>
<font style="background-color: #E6E6FA;">[](/papers/HigDimen/2-code.pdf)</font>
-->
<h2 id="高维数据-https-tang-jay-github-io-highdimen"><a href="https://tang-jay.github.io/HighDimen">高维数据</a></h2>
<p><code>2007</code>. 石坚. <a href="/papers/HigDimen/ShiJ-2007.pdf"><code>高维线性模型中的经验似然</code></a>.
<a href="/papers/HigDimen/Ghosh-1984.pdf"><code>文献5</code></a>.<a href="/papers/HigDimen/ShiJ-2000.pdf"><code>文献6</code></a>.<a href="/papers/HigDimen/Peter-1987.pdf"><code>文献7</code></a>
<a href="/papers/HigDimen/ShiJ-2007-note.pdf">✓</a></p>
<p><code>2009</code>. Hjort. <a href="/papers/HigDimen/Hjort-2009.pdf"><code>拓展经验似然范围</code></a></p>
<p><code>2009</code>. 秦YL. <a href="/papers/HigDimen/QinYL-2009.pdf"><code>高维数据统计推断</code></a></p>
<p><code>2009</code>. 陈松溪, 彭亮, 秦YL. <a href="/papers/HigDimen/ChenSX-2009.pdf"><code>数据维数对经验似然的影响</code></a>
<a href="/papers/HigDimen/ChenSX-2009-note.pdf">✓</a></p>
<p><code>2010</code>. <a href="https://xs2.zidianzhan.net/citations?user=lZUH1lcAAAAJ&amp;hl=zh-CN&amp;oi=sra">汤琤咏</a>, 冷琛雷. <a href="/papers/HigDimen/TangCY-2010.pdf"><code>高维惩罚经验似然</code></a>
<a href="/papers/HigDimen/TangCY-2010-note.pdf">✓</a></p>
<p><code>2012</code>. <a href="https://xs2.zidianzhan.net/citations?user=rsT2stMAAAAJ&amp;hl=zh-CN&amp;oi=sra">冷琛雷</a>, 汤琤咏. <a href="/papers/HigDimen/LengCL-2012.pdf"><code>惩罚经验似然与高维估计方程</code></a>
<a href="/papers/HigDimen/LengCL-2012-note.pdf">✓</a></p>
<p><code>2013</code>. <a href="https://xueshu.studiodahu.com/citations?user=6z-xg3AAAAAJ&amp;hl=zh-CN&amp;oi=sra">Wang ZJ</a>. <a href="/papers/HigDimen/WangZJ-2013.pdf"><code>高维回归模型的校正经验似然</code></a></p>
<p><code>2013</code>. <a href="https://xueshu.zidianzhan.net/citations?user=61q2xTYAAAAJ&amp;hl=zh-CN&amp;oi=sra">Heng Lian</a>. <a href="/papers/HigDimen/HengL-2013.pdf"><code>高维删失情形下部分线性比率危险模型的经验似然</code></a></p>
<p><code>2014</code>. Nordmana, Lahiri. <a href="/papers/HigDimen/Nordmana-2014.pdf"><code>一篇综述关于经验似然方法应用于时间序列</code></a>
<a href="/papers/HigDimen/Nordmana-2014-note.pdf">✓</a></p>
<p><code>2015</code>. 常晋源, 陈松溪. <a href="/papers/HigDimen/ChangJY-2015.pdf"><code>高维一般经验似然于相依数据矩约束</code></a></p>
<p><code>2017</code>. 常晋源, 陈松溪. <a href="/papers/HigDimen/ChangJY-2017.pdf"><code>高维经验似然估计方程新范围</code></a></p>
<p><code>2020</code>. 常晋源, 陈松溪, 汤琤咏. <a href="/papers/HigDimen/ChangJY-2020.pdf"><code>数据经验似然推断</code></a></p>
<p><code>2018</code>. 陈夏. <a href="/papers/HigDimen/ChenX-2018-1.pdf"><code>高维广义线性模型的惩罚拟似然SCAD估计</code></a></p>
<p><code>2018</code>. 陈夏. <a href="/papers/HigDimen/ChenX-2018-2.pdf"><code>固定和自适应设计下高维广义线性模型的经验似然检验</code></a></p>
<p><code>2020</code>. 张金廷. <a href="/papers/HigDimen/ZhangJT-2020.pdf"><code>基于L2范数的高维数据双因素方差分析方法</code></a></p>
<p><code>2020</code>. 周杰. <a href="/papers/HigDimen/ZhouJ-2020.pdf"><code>基于随机矩阵理论的高维数据球形检验</code></a></p>
<p><code>2021</code>. 刘锋. <a href="/papers/HigDimen/LiuF-2021.pdf"><code>高维数据下线性模型的序列相关检验</code></a></p>
<h2 id="硕博论文">硕博论文</h2>
<ul>
<li>
<p>周雅诗. <a href="/papers/HigDimen/%E5%91%A8%E9%9B%85%E8%AF%97.pdf"><code>关于高维协方差矩阵迹的若干估计</code></a></p>
</li>
<li>
<p>胡浩. <a href="/papers/HigDimen/%E8%83%A1%E6%B5%A9.pdf"><code>一种新的高维两样本均值检验</code></a></p>
</li>
<li>
<p>唐莹莹. <a href="/papers/HigDimen/%E5%94%90%E8%8E%B9%E8%8E%B9.pdf"><code>两类空间面板数据模型的变量选择</code></a></p>
</li>
<li>
<p>马昀蓓. <a href="/papers/HigDimen/%E9%A9%AC%E6%98%80%E8%93%93.pdf"><code>相依误差下线性模型的经验似然</code></a></p>
</li>
<li>
<p>文怡方. <a href="/papers/HigDimen/%E6%96%87%E6%80%A1%E6%96%B9.pdf"><code>部分函数型线性模型的高维惩罚经验似然</code></a></p>
</li>
<li>
<p>刘琦. <a href="/papers/HigDimen/%E5%88%98%E7%90%A6.pdf"><code>广义线性模型的高维惩罚经验似然</code></a></p>
</li>
<li>
<p>王富雅. <a href="/papers/HigDimen/%E7%8E%8B%E5%AF%8C%E9%9B%85.pdf"><code>海量高维数据的分位数回归</code></a></p>
</li>
<li>
<p>曾云辉. <a href="/papers/HigDimen/%E6%9B%BE%E4%BA%91%E8%BE%89.pdf"><code>高维线性模型和部分线性模型的相合统计推断</code></a></p>
</li>
<li>
<p>马莹莹. <a href="/papers/HigDimen/%E9%A9%AC%E8%8E%B9%E8%8E%B9.pdf"><code>高维数据均值和协差阵检验的经验似然方法</code></a></p>
</li>
<li>
<p>李玲玲. <a href="/papers/HigDimen/%E6%9D%8E%E7%8E%B2%E7%8E%B2.pdf"><code>高维线性模型的变量选择</code></a></p>
</li>
<li>
<p>慕娟. <a href="/papers/HigDimen/%E6%85%95%E5%A8%9F.pdf"><code>高维变点模型自适应GroupLasso惩罚分位回归估计</code></a></p>
</li>
<li>
<p>胡玉婷. <a href="/papers/HigDimen/%E8%83%A1%E7%8E%89%E5%A9%B7.pdf"><code>高维两样本比对问题的一种新统计检验方法</code></a></p>
</li>
<li>
<p>李扬. <a href="/papers/HigDimen/%E6%9D%8E%E6%89%AC.pdf"><code>高维数据的正态性假设检验</code></a></p>
</li>
<li>
<p>邓语菲. <a href="/papers/HigDimen/%E9%82%93%E8%AF%AD%E8%8F%B2.pdf"><code>高维数据下的单指标期望分位数回归模型研究</code></a></p>
</li>
<li>
<p>江梦婕. <a href="/papers/HigDimen/%E6%B1%9F%E6%A2%A6%E5%A9%95.pdf"><code>高维数据下的多元均值检验</code></a></p>
</li>
<li>
<p>王一静. <a href="/papers/HigDimen/%E7%8E%8B%E4%B8%80%E9%9D%99.pdf"><code>高维数据下的协方差和总体均值检验</code></a></p>
</li>
<li>
<p>李熠璇. <a href="/papers/HigDimen/%E6%9D%8E%E7%86%A0%E7%92%87.pdf"><code>高维数据下正态总体的假设检验问题</code></a></p>
</li>
<li>
<p>袁百城. <a href="/papers/HigDimen/%E8%A2%81%E7%99%BE%E5%9F%8E.pdf"><code>高维数据总体双可交换协方差矩阵的似然比检验</code></a></p>
</li>
<li>
<p>邹婷婷. <a href="/papers/HigDimen/%E9%82%B9%E5%A9%B7%E5%A9%B7.pdf"><code>高维协方差矩阵的单样本和双样本检验方法</code></a></p>
</li>
<li>
<p>向邱燕. <a href="/papers/HigDimen/%E5%90%91%E9%82%B1%E7%87%95.pdf"><code>基于稀疏张量回归的高维数据预测</code></a></p>
</li>
<li>
<p>杨静. <a href="/papers/HigDimen/%E6%9D%A8%E9%9D%99.pdf"><code>基于置换检验对高维数据两样本均值的假设检验</code></a></p>
</li>
<li>
<p>曾銮杰. <a href="/papers/HigDimen/%E6%9B%BE%E9%8A%AE%E6%9D%B0.pdf"><code>基于bootstrap方法的高维数据两样本均值检验</code></a></p>
</li>
<li>
<p>贾婉茹. <a href="/papers/HigDimen/%E8%B4%BE%E5%A9%89%E8%8C%B9.pdf"><code>基于bootstrap方法Behrens-Fisher问题的假设检验</code></a></p>
</li>
</ul>

        
        ]]>
      </description>
    </item>
    
    
    
    <item>
      <title>空间文献摘录</title>
      <link>/cn/2022/10/21/spamodel/</link>
      <pubDate>Fri, 21 Oct 2022 00:00:00 +0000</pubDate>
      <author>Tan Jay</author>
      <guid>/cn/2022/10/21/spamodel/</guid>
      <description>
        <![CDATA[
        <h2 id="空间模型">空间模型</h2>
<h3 id="秦永松-https-xueshu-zidianzhan-net-scholar-hl-zh-cn-as-sdt-0-2c5-q-ys-qin-empirical-likelihood-btng"><a href="https://xueshu.zidianzhan.net/scholar?hl=zh-CN&amp;as_sdt=0%2C5&amp;q=YS+Qin+empirical+likelihood&amp;btnG=">秦永松</a></h3>
<p><code>2021</code> <a href="/papers/SpaModel/QinYS-2021-1.pdf"><code>含空间误差项的空间自回归模型的经验似然</code></a></p>
<blockquote>
<p>经验似然方法成功应用空间模型的奠基之作。</p>
</blockquote>
<p><code>2021</code> <a href="/papers/SpaModel/QinYS-2021-2.pdf"><code>三种空间截面数据模型的GMM与经验似然</code></a></p>
<p><code>2022</code> <a href="/papers/SpaModel/QinYS-2022.pdf"><code>空间计量经济模型的经验似然研究进展</code></a></p>
<blockquote>
<p>这是一篇经验似然方法应用于空间模型的综述。</p>
</blockquote>
<h3 id="李英华">李英华</h3>
<p><code>2020</code> <a href="/papers/SpaModel/LiYH-2020.pdf"><code>含空间误差项的面板数据模型的经验似然</code></a></p>
<p><code>2021</code> <a href="/papers/SpaModel/LiYH-2021.pdf"><code>含空间误差项的非参数回归模型的经验似然</code></a></p>
<p><code>2022</code> <a href="/papers/SpaModel/LiYH-2022.pdf"><code>含空间误差项的动态面板数据模型的经验似然</code></a></p>

        
        ]]>
      </description>
    </item>
    
    
    
    <item>
      <title>面板文献摘录</title>
      <link>/cn/2022/10/20/panempir/</link>
      <pubDate>Thu, 20 Oct 2022 00:00:00 +0000</pubDate>
      <author>Tan Jay</author>
      <guid>/cn/2022/10/20/panempir/</guid>
      <description>
        <![CDATA[
        <h2 id="面板数据-https-xs2-zidianzhan-net-scholar-hl-zh-cn-as-sdt-0-2c5-q-panel-data-btng"><a href="https://xs2.zidianzhan.net/scholar?hl=zh-CN&amp;as_sdt=0%2C5&amp;q=panel+data&amp;btnG=">面板数据</a></h2>
<h3 id="何帮强-https-kns-cnki-net-kcms-detail-knetsearch-aspx-dbcode-cjfd-code-000021434404-sfield-au-skey-何帮强-uniplatform-nzkpt"><a href="https://kns.cnki.net/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;code=000021434404&amp;sfield=au&amp;skey=%E4%BD%95%E5%B8%AE%E5%BC%BA&amp;uniplatform=NZKPT">何帮强</a></h3>
<p><a href="/papers/HigDimen/%E4%BD%95%E5%B8%AE%E5%BC%BA.pdf"><code>带固定效应 + 面板数据 + 半参数模型 + 经验似然</code></a></p>
<blockquote>
<p>此篇博士论文中研究了，带固定效应面板数据半参数模型的经验似然问题。</p>
</blockquote>
<p><a href="/papers/PanEmpir/HeBQ-2016-1.pdf"><code>带固定效应 + 面板数据 + 半变系数模型 + 经验似然</code></a></p>
<p><a href="/papers/PanEmpir/HeBQ-2017.pdf"><code>带固定效应 + 面板数据 + 部分线性模型 + 块经验似然</code></a></p>
<!--
[`随机审查下pareto分布参数的单调经验贝叶斯检验`](/papers/PanEmpir/HeBQ-2016-2.pdf)  
-->
<p><a href="/papers/PanEmpir/HeBQ-2021.pdf"><code>带固定效应 + 面板数据 + 部分线性误差变量模型 + 统计推断</code></a></p>
<p><a href="/papers/PanEmpir/HeBQ-2018.pdf"><code>带固定效应 + 面板数据 + 部分线性误差变量模型 + 惩罚经验似然</code></a></p>
<p><a href="/papers/PanEmpir/HeBQ-2020.pdf"><code>鞅差序列 + 非线性半参数测量误差模型 + 经验似然</code></a></p>
<p><a href="/papers/PanEmpir/HeBQ-2022.pdf"><code>删失数据 + 面板数据 + 半变系数变量误差模型 + 经验似然</code></a></p>
<h3 id="李高荣-https-xueshu-zidianzhan-net-citations-user-cakqlosaaaaj-hl-zh-cn-oi-sra-1"><a href="https://xueshu.zidianzhan.net/citations?user=cakQLOsAAAAJ&amp;hl=zh-CN&amp;oi=sra">李高荣</a> <sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup></h3>
<p><a href="/papers/PanEmpir/LiGR-2011.pdf"><code>带固定效应 + 面板数据 + 部分线性模型 + 经验似然</code></a></p>
<p><a href="/papers/HigDimen/LiGR-2012.pdf"><code>高维 + 截面数据 + 变系数部分线性模型 + 经验似然</code></a></p>
<blockquote>
<p>方江林提到，该文提出了改进的经验似然方法可以提高其统计推断的效率。</p>
</blockquote>
<h3 id="baltagi-badi-h-https-xueshu-zidianzhan-net-citations-user-xwrdl6iaaaaj-hl-zh-cn-oi-sra"><a href="https://xueshu.zidianzhan.net/citations?user=XWrDL6IAAAAJ&amp;hl=zh-CN&amp;oi=sra">Baltagi, Badi H</a></h3>
<p><code>2003</code> <a href="/papers/PanEmpir/BaltagiBH-2003.pdf"><code>空间自回归误差项 + 面板数据 + 线性模型 + 似然比检验</code></a></p>
<blockquote>
<p>先做一种检验问题的似然<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>检验和经验似然检验的模拟研究，并进行比较。</p>
</blockquote>
<p><code>2021</code> <a href="/papers/PanEmpir/BaltagiBH-2021.pdf"><code>面板数据的计量分析</code></a></p>
<!--
[`Monotone empirical bayes test for the parameter of pareto distribution under random censorship
`](/papers/PanEmpir/HeBQ-3.pdf)

> 题外话，一不留神，开学两个月了，啥也没弄出来，顿挫感一下子就上来了。这学期还计划写一篇有意义的论文呢，现在看来，长路漫漫了。一方面呢，要保持顿挫感，它督促我珍惜时间继续努力，另一方面，不能让顿挫感泛滥，这会让我陷入无限的自责。
--><div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>公众号：<em>郭老师统计小课堂</em>。<a href="https://mp.weixin.qq.com/s/k_nRP6l19zEXPvEyKrMhmw">似然函数的分解和重参数化</a>&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p>公众号：<em>数据挖掘工程师</em>。<a href="https://mp.weixin.qq.com/s/mWJGGAIKfz9itAux76bLiA">最大似然估计入门教程</a>&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>

        
        ]]>
      </description>
    </item>
    
    
    
    <item>
      <title>高维可尝试方向</title>
      <link>/cn/2022/10/17/higdim/</link>
      <pubDate>Mon, 17 Oct 2022 00:00:00 +0000</pubDate>
      <author>Tan Jay</author>
      <guid>/cn/2022/10/17/higdim/</guid>
      <description>
        <![CDATA[
        <h2 id="高维问题">高维问题</h2>
<p>曾力立说，</p>
<ol>
<li>传统的数据处理方法在处理高维数据时不能满足稳健性要求；</li>
<li>高维导致空间的样本数变少，从而使得一些统计上的渐近性难以实现；</li>
<li>维数的增加亦会导致数据的计算量迅速上升。</li>
</ol>
<p>方江林说，</p>
<ol>
<li>维数的增大会导致“维数灾难”问题；</li>
<li>经典大样本统计推断理论一般都是建立在维数固定且相对较小，而样本量趋于无穷的假设下，在数据维数p随着样本容量n一起趋向无穷时，特别是在“超高维”(p &gt; n)数据情形下，经典统计理论的结论可能不再有效。</li>
</ol>
<h2 id="方向">方向</h2>
<h3 id="方向一">方向一</h3>
<p>根据 <strong>石坚</strong><a href="/papers/HigDimen/2.pdf">《高维线性模型中的经验似然》</a>思想，说明高维空间模型中，在适当的正则条件下，可对经验似然比统计量进行修正，并且修正后的经验似然比统计量服从标准正态分布。</p>
<p>实际进展<a href="https://tang-jay.github.io/HighDimen">见此</a>。</p>
<h3 id="方向二">方向二</h3>
<p>当 <code>$\beta$</code> 有很多分量为零，可以做变量选择，比如Lasso、惩罚经验似然，先选出非零的分量，然后对被选出来的非零分量做统计推断。</p>
<h3 id="方向三">方向三</h3>
<p>当 <code>$\beta$</code> 有很多分量不为零，简单地考虑变量选择是不够的，根据 <strong>曾力立</strong><a href="/papers/HigDimen/%E6%9B%BE%E5%8A%9B%E7%AB%8B.pdf">《高维线性回归模型下的经验似然》</a>思想，说明高维空间模型中可以建立简单经验似然统计量，并且证明该统计量服从 <code>$\chi^2_1$</code>，从模拟的角度说明，犯两类错误的概率令人满意，且大大节省了计算成本。</p>

        
        ]]>
      </description>
    </item>
    
    
    
    <item>
      <title>高维文献摘录</title>
      <link>/cn/2022/10/16/higdimen/</link>
      <pubDate>Sun, 16 Oct 2022 00:00:00 +0000</pubDate>
      <author>Tan Jay</author>
      <guid>/cn/2022/10/16/higdimen/</guid>
      <description>
        <![CDATA[
        <!-- 
- [``](/papers/HigDimen/曾力立.pdf)
<font style="background-color: #FFFFCD;">[`PDF`](/papers/HigDimen/2.pdf)</font>
<font style="background-color: #F0FFFF;">[`NOTE`](/papers/HigDimen/2-note.pdf)</font>
<font style="background-color: #E6E6FA;">[](/papers/HigDimen/2-code.pdf)</font>
> 
-->
<h2 id="奠基">奠基</h2>
<ul>
<li>石坚. <a href="/papers/HigDimen/ShiJ-2007.pdf"><code>高维线性模型中的经验似然</code></a></li>
</ul>
<blockquote>
<p>当协变量的维数随样本量增加时，常规的经验似然推断失效，在适当的正则条件下，对修正的经验似然比统计量给出了渐近分布理论。</p>
</blockquote>
<blockquote>
<p>曾力立提到，该论文表明，当协变量维数以某种合理的速度趋于无穷大时，我们仍可以利用经验似然方法构造 <code>$\beta$</code> 的置信域，不过此时有关临界值的确定依赖于正态分布而非卡方分布。</p>
</blockquote>
<ul>
<li><a href="https://xueshu.zidianzhan.net/citations?user=pGvWCH4AAAAJ&amp;hl=zh-CN&amp;oi=sra">Hjort et al.</a> <a href="/papers/HigDimen/Hjort-2009.pdf"><code>拓展经验似然应用范围</code></a></li>
</ul>
<blockquote>
<p>方江林提到，当 <code>$p=o_p(n^{1/3}) \to \infty$</code> 时，在一定条件下，该文得出了经验似然比统计量渐近分布为正态分布的结论。</p>
</blockquote>
<blockquote>
<p>曾力立提到，该文在基于plug-in估计对经验似然方法做了一个推广研究。</p>
</blockquote>
<ul>
<li>陈松溪，<a href="https://xueshu.zidianzhan.net/citations?user=b3XlCawAAAAJ&amp;hl=zh-CN&amp;oi=sra">彭亮</a>. <a href="/papers/HigDimen/ChenSX-2009.pdf"><code>数据维数对经验似然的影响</code></a></li>
</ul>
<blockquote>
<p>在一般的多元模型下，该文评估了数据维数对高维数据经验似然比的渐近正态性的影响，指出多元随机向量各分量之间的数据维数和相关性直接通过协方差矩阵的迹和特征值来影响经验似然。</p>
</blockquote>
<blockquote>
<p>方江林提到，该文是在Hjort基础上，进一步研究了样本维数对经验似然方法的影响，证明了当 <code>$p=o_p(n^{1/2}) \to \infty$</code> 时，经验似然方法仍然适用，改进了Hjort的结果。</p>
</blockquote>
<blockquote>
<p>曾力立提到，该文在多元模型下研究了均值的渐近性质。</p>
</blockquote>
<blockquote>
<p>毛沥悦提到，该文证明了当参数的维数变化时，经验似然方法仍然有效。</p>
</blockquote>
<ul>
<li>常晋源，陈松溪，汤琤咏. <a href="/papers/HigDimen/ChangJY-2020.pdf"><code>高维经验似然推断</code></a></li>
</ul>
<blockquote>
<p>研究两个问题，多元参数估计量的置信域和模型假设检验，并提出两个建议，新的估计方程和检验统计量。</p>
</blockquote>
<ul>
<li><a href="https://xs2.zidianzhan.net/citations?user=lZUH1lcAAAAJ&amp;hl=zh-CN&amp;oi=sra">汤琤咏</a>，冷琛雷. <a href="/papers/HigDimen/TangCY-2010.pdf"><code>高维惩罚经验似然</code></a></li>
</ul>
<blockquote>
<p>方江林提到，该类惩罚的思想是在进行参数估计的同时，利用惩罚函数将较小的系数估计值压缩为零，而将系数估计值较大的保留，在估计出系数的同时选择出重要变量。这可以同时实现变量选择和系数估计两个目标。惩罚变量选择普遍采用“损失函数+惩罚函数”的变量选择方法，类似地，惩罚经验似然通常也使用“经验似然比函数+惩罚函数”方式。该文首次将惩罚经验似然方法应用于高维，不过要求在 <code>$p &lt; n$</code> 情形下。</p>
</blockquote>
<blockquote>
<p>曾力立提到，该文将经验似然应用于高维变量选择。</p>
</blockquote>
<blockquote>
<p>何帮强提到，该文首次提出的惩罚经验似然（PEL）被用于分析多变量的均值向量和线性模型的发散数量回归系数。该文证实的PEL具有优点在来自非参数似然法的效率和适应性方面。另外，PEL方法具有使用数据来确定置信区域的形状和取向，与EL有相同优点并且不估计共协方差。</p>
</blockquote>
<ul>
<li><a href="https://xs2.zidianzhan.net/citations?user=rsT2stMAAAAJ&amp;hl=zh-CN&amp;oi=sra">冷琛雷</a>，汤琤咏. <a href="/papers/HigDimen/LengCL-2012.pdf"><code>惩罚经验似然与高维估计方程</code></a></li>
</ul>
<blockquote>
<p>方江林提到，该文将高维的惩罚经验似然方法推广到高维估计方程，仍要求<code>$p &lt; n$</code>。</p>
</blockquote>
<blockquote>
<p>何帮强提到，该文将PEL方法应用于一般估计方程的参数估计和变量选择，并显示PEL具有oracle特征。</p>
</blockquote>
<ul>
<li><a href="https://xs2.zidianzhan.net/citations?user=I5ZzKjAAAAAJ&amp;hl=zh-CN&amp;oi=sra">Lahiri</a>， <a href="https://xs2.zidianzhan.net/citations?user=Wf3jLKoAAAAJ&amp;hl=zh-CN&amp;oi=sra">Mukhopadhyay</a>. <a href="/papers/HigDimen/Lahiri-2012.pdf"><code>高维中一种惩罚经验似然</code></a></li>
</ul>
<blockquote>
<p>方江林提到，当维数是超高维的，即 <code>$p &gt; n$</code> 时，该文研究了总体均值的惩罚经验似然推断，并给出了其统计量的渐近性质。</p>
</blockquote>
<ul>
<li><a href="https://xueshu.zidianzhan.net/citations?user=cakQLOsAAAAJ&amp;hl=zh-CN&amp;oi=sra">李高荣</a>. <a href="/papers/HigDimen/LiGR-2012.pdf"><code>高维变系数部分线性模型的经验似然</code></a></li>
</ul>
<blockquote>
<p>方江林提到，该文提出了改进的经验似然方法可以提高其统计推断的效率。</p>
</blockquote>
<ul>
<li><a href="https://xs2.zidianzhan.net/citations?user=sdw9roIAAAAJ&amp;hl=zh-CN&amp;oi=sra">Meinshausen N</a>. <a href="/papers/HigDimen/MeinshausenN-2009.pdf"><code>高维回归p值</code></a></li>
</ul>
<blockquote>
<p>曾力立提到，该文研究了高维线性回归模型中的变量选择问题。</p>
</blockquote>
<h2 id="经验似然">经验似然</h2>
<ul>
<li>曾力立. <a href="/papers/HigDimen/%E6%9B%BE%E5%8A%9B%E7%AB%8B.pdf"><code>高维线性回归模型下的经验似然</code></a></li>
</ul>
<blockquote>
<p>许多经典的低维数据处理方法，在处理髙维数据时面临着难以解决的困难。例如，传统的数据处理方法在处理高维数据时不能满足稳健性要求；高维导致空间的样本数变少，从而使得一些统计上的渐近性难以实现；维数的增加亦会导致数据的计算量迅速上升。</p>
</blockquote>
<blockquote>
<p>在这篇论文里，作者的主要目的是检验一个可能的高维线性回归模型的系数是否等于一个给定值。创新点：</p>
<ol>
<li>将传统经验似然方法里面的高维约束条件巧妙地变换成与维数无关的低维情形，以此构造出新的约束条件，再利用经验似然的方法解决相关问题。</li>
<li>在一般经验似然方法里加入了伪观测值，从而作出了一个新奇的调整。调整后的经验似然方法保留了之前方法的所有最优性准则．不仅如此，该方法下的区间覆盖率更接近于置信水平，而且还不需要Bartlett校正和Bootstrap方法里那么复杂的程序。</li>
<li>针对不同的维数，有区别地加入了约束条件的个数，一方面使得犯两类错误的概率令人满意，另一方面也大大地节省了计算成本。</li>
</ol>
</blockquote>
<blockquote>
<p>该文指出，线性模型的统计推断中 <code>$p$</code> 是 <code>$n$</code> 的指数阶的情况下的研究现状：</p>
<ol>
<li><code>$\beta$</code> 有很多分量为零，首先选出非零的分量（即变量选择，如Lasso），然后对被选出来的非零分量做统计推断。</li>
<li><code>$\beta$</code> 有很多分量不为零，简单地考虑变量选择是不够的，需要新的方法，借鉴<a href="https://xueshu.zidianzhan.net/citations?user=b3XlCawAAAAJ&amp;hl=zh-CN&amp;oi=sra">彭亮</a>在 <a href="/papers/NBEL/PengL-2014-1.pdf"><em>Empirical likelihood test for high dimensional linear models</em></a> 一文中的思想，通过一定手段——将样本数据分为两个部分，用每两个旧的观测值构造一个新的观测值——将约束条件与维数无关。</li>
</ol>
</blockquote>
<blockquote>
<p>该文思路：利用已有的观测值去构造 <code>$\omega_i(\beta)$</code>，构造出来的 <code>$\omega_i(\beta)$</code>需满足</p>
<ol>
<li><code>$E\omega_i(\beta_0)=0$</code>；</li>
<li><code>$E\omega_i(\beta_0)=0$</code> 非常接近于<code>$L_1$</code>范数。</li>
</ol>
</blockquote>
<blockquote>
<p>由此将经验似然的方法应用于估计式及 <code>$E\omega_i(\beta_0)=0$</code>，从而解决 <code>$\beta$</code> 有很多分量不为零的假设检验问题。曾力立将高维转换为一维进行考虑，并称其为简单经验似然。</p>
</blockquote>
<ul>
<li>方江林. <a href="/papers/HigDimen/%E6%96%B9%E6%B1%9F%E6%9E%97.pdf"><code>维数发散的高维数据的经验似然</code></a></li>
</ul>
<blockquote>
<p>在样本维数 <code>$p$</code> 随容量 <code>$n$</code> 一起趋向无穷的情形下，本文研究了多个模型的经验似然推断，分别有半参数模型，可加危险率模型，异方差部分线性单指标模型，以及两样本问题（均值，线性模型系数之差）。</p>
</blockquote>
<blockquote>
<p>具体工作：</p>
<ol>
<li>利用经验似然方法构造了参数的估计量及其置信域。证明了在一定条件下，当样本维数和容量都趋向无穷情形时，经验似然比渐近分布为正态分布，并证明了通过经验似然方法得到的参数估计量具有一致性。</li>
<li>利用经验似然方法构造了参数分量的置信区间(置信域)。证明了在一定条件下，当样本维数发散时，通过经验似然方法得到的参数估计量具有一致性，并证明了关于参数分量的经验似然比渐近分布是 <code>$\chi^2_q$</code> 分布。</li>
<li>将惩罚经验似然方法推广到高维稀疏情形下模型的变量选择和参数估计问题。证明了在一定条件下，当样本维数发散时，惩罚经验似然比统计量具有渐近 <code>$\chi^2_q$</code> 分布，同时证明了惩罚经验似然方法具有Oracle性质。</li>
</ol>
</blockquote>
<blockquote>
<p>发表论文：</p>
<ol>
<li>方江林，<a href="https://mc.hunnu.edu.cn/info/1673/3366.htm">刘万荣</a>，<a href="https://xueshu.zidianzhan.net/citations?user=3yVTsEEAAAAJ&amp;hl=zh-CN&amp;oi=sra">Lu Xuewen</a>. <a href="/papers/HigDimen/FangJL-2017.pdf"><code>半参数模型的高维惩罚经验似然</code></a></li>
</ol>
</blockquote>
<h2 id="惩罚经验似然">惩罚经验似然</h2>
<ul>
<li>毛沥悦. <a href="/papers/HigDimen/%E6%AF%9B%E6%B2%A5%E6%82%A6.pdf"><code>部分线性模型和广义线性模型的惩罚经验似然</code></a></li>
</ul>
<blockquote>
<p>第三章讨论高维情况下广义线性模型的参数估计与变量选择问题，通过通过适当的辅助随机变量研究了自适应Lasso下高维广义线性模型的惩罚经验似然。主要的结论有提出的方法具有Oracle性质以及在假设检验中构造的检验统计量的渐近分布为卡方分布。</p>
</blockquote>
<ul>
<li>吕升日. <a href="/papers/HigDimen/%E5%90%95%E5%8D%87%E6%97%A5.pdf"><code>半参数回归模型的高维惩罚经验似然</code></a></li>
</ul>
<blockquote>
<p>在半参数回归模型中，当协变量的维度随着样本量的增大而增大，即当协变量维度较高时，将会遇到“维数祸根”等问题。将经验似然方法与惩罚函数相结合并应用于模型当中，可以有效的解决高维数据情况下的变量选择问题，从而降低模型的复杂度，解决模型在做预测时的不稳定性的问题。</p>
</blockquote>
<ul>
<li>何帮强. <a href="/papers/HigDimen/%E4%BD%95%E5%B8%AE%E5%BC%BA.pdf"><code>半参数带固定效应的面板数据模型的经验似然</code></a></li>
</ul>
<blockquote>
<p>何帮强更多面板研究成果<a href="/cn/2022/10/20/panel">见此</a>。</p>
</blockquote>
<ul>
<li>李吉妮. <a href="/papers/HigDimen/%E6%9D%8E%E5%90%89%E5%A6%AE.pdf"><code>单指标模型的高维惩罚经验似然</code></a></li>
</ul>
<blockquote>
<p>高维数据的变量选择问题。在处理高维数据时，单指标模型的降维特性有效地避免了“维数灾难问题，还抓住了高维数据的稀疏特性。在论文中考虑参数维数会随着样本容量的增大而同时增大的情形，对单指标模型提出了一种稳健的变量选择方法：基于SCAD惩罚函数及经验似然的惩罚经验似然。</p>
</blockquote>
<blockquote>
<p>论文发现，在一定正则条件下，参数维数随样本量同时增大的惩罚经验似然估计仍具有Oracle性质，即如果已知真实模型是稀疏的模型，则以概率趋向于1，惩罚经验似然确定模型的非零参数估计具有稀疏性（惩罚似然估计值应该有一个限制，这个限制自动将那些较小的估计系数设为，进而去掉，并删除对应的变量，从而降低模型的复杂度）。</p>
</blockquote>

        
        ]]>
      </description>
    </item>
    
    
    
    <item>
      <title>对称矩阵</title>
      <link>/cn/2022/09/22/symmatrix/</link>
      <pubDate>Thu, 22 Sep 2022 00:00:00 +0000</pubDate>
      <author>Tan Jay</author>
      <guid>/cn/2022/09/22/symmatrix/</guid>
      <description>
        <![CDATA[
        <blockquote>
<p>Hessian矩阵、协方差矩阵、空间权重矩阵都是对称矩阵，相关的性质有必要了解一下。</p>
</blockquote>
<hr>
<h3 id="对称矩阵">对称矩阵</h3>
<ol>
<li><a href="https://mp.weixin.qq.com/s/mTiT8wNovGGAawlO-608_w">矩阵二次型及其性质</a></li>
<li><a href="/papers/SymMatrix/%E5%AF%B9%E7%A7%B0%E7%9F%A9%E9%98%B5%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%A7%E8%B4%A8%E5%92%8C%E5%AE%9A%E7%90%86_%E9%9F%A9%E6%8C%AF%E8%8A%B3.pdf">对称矩阵的一些性质和定理_韩振芳.pdf</a></li>
<li><a href="/papers/SymMatrix/%E5%AF%B9%E7%A7%B0%E7%9F%A9%E9%98%B5%E7%9A%84%E6%80%A7%E8%B4%A8%E5%8F%8A%E5%BA%94%E7%94%A8_%E5%8F%B8%E5%87%A4%E5%A8%9F.pdf">对称矩阵的性质及应用_司凤娟.pdf</a></li>
<li><a href="/papers/SymMatrix/%E5%AF%B9%E7%A7%B0%E7%9F%A9%E9%98%B5%E6%95%99%E4%B8%8E%E5%AD%A6_%E7%8E%8B%E5%AE%8F%E5%85%B4.pdf">对称矩阵教与学_王宏兴.pdf</a></li>
</ol>
<h3 id="反对称矩阵">反对称矩阵</h3>
<ol>
<li><a href="/papers/SymMatrix/%E5%AF%B9%E7%A7%B0%E7%9F%A9%E9%98%B5%E4%B8%8E%E5%8F%8D%E5%AF%B9%E7%A7%B0%E7%9F%A9%E9%98%B5%E7%9A%84%E8%8B%A5%E5%B9%B2%E6%80%A7%E8%B4%A8_%E6%AD%A6%E7%A7%80%E7%BE%8E.pdf">对称矩阵与反对称矩阵的若干性质_武秀美.pdf</a></li>
<li><a href="/papers/SymMatrix/%E5%AF%B9%E7%A7%B0%E7%9F%A9%E9%98%B5%E5%92%8C%E5%8F%8D%E5%AF%B9%E7%A7%B0%E7%9F%A9%E9%98%B5%E7%9A%84%E8%8B%A5%E5%B9%B2%E6%80%A7%E8%B4%A8_%E9%82%B9%E6%9C%AC%E5%BC%BA.pdf">对称矩阵和反对称矩阵的若干性质_邹本强.pdf</a></li>
<li><a href="/papers/SymMatrix/%E5%85%B3%E4%BA%8E%E5%AF%B9%E7%A7%B0%E7%9F%A9%E9%98%B5%E4%B8%8E%E5%8F%8D%E5%AF%B9%E7%A7%B0%E7%9F%A9%E9%98%B5%E7%9A%84%E8%8B%A5%E5%B9%B2%E6%80%A7%E8%B4%A8_%E6%9C%B1%E4%BA%9A%E8%8C%B9.pdf">关于对称矩阵与反对称矩阵的若干性质_朱亚茹.pdf</a></li>
</ol>
<h3 id="非对称矩阵">非对称矩阵</h3>
<ol>
<li><a href="/papers/SymMatrix/%E9%9D%9E%E5%AF%B9%E7%A7%B0%E6%AD%A3%E5%AE%9A%E7%9F%A9%E9%98%B5%E7%9A%84%E6%80%A7%E8%B4%A8_%E7%8E%8B%E4%B8%96%E6%81%92.pdf">非对称正定矩阵的性质_王世恒.pdf</a></li>
</ol>
<h3 id="对称矩阵应用">对称矩阵应用</h3>
<ol>
<li><a href="/papers/SymMatrix/%E5%AE%9E%E5%AF%B9%E7%A7%B0%E7%9F%A9%E9%98%B5%E7%9A%84%E6%80%A7%E8%B4%A8%E5%8F%8A%E5%85%B6%E5%BA%94%E7%94%A8_%E8%96%9B%E5%BB%BA%E6%98%8E.pdf">实对称矩阵的性质及其应用_薛建明.pdf</a></li>
<li><a href="/papers/SymMatrix/%E5%AE%9E%E5%AF%B9%E7%A7%B0%E7%9F%A9%E9%98%B5%E7%89%B9%E5%BE%81%E5%80%BC%E7%9A%84%E6%80%A7%E8%B4%A8%E5%8F%8A%E5%85%B6%E5%BA%94%E7%94%A8_%E6%9D%A8%E5%8F%AC.pdf">实对称矩阵特征值的性质及其应用_杨召.pdf</a></li>
</ol>
<h3 id="特征向量求法">特征向量求法</h3>
<ol>
<li><a href="/papers/SymMatrix/%E8%AE%A1%E7%AE%97%E5%AE%9E%E5%AF%B9%E7%A7%B0%E7%9F%A9%E9%98%B5%E7%89%B9%E5%BE%81%E5%80%BC%E7%89%B9%E5%BE%81%E5%90%91%E9%87%8F%E7%9A%84%E5%B9%82%E6%B3%95_%E6%9B%BE%E8%8E%89.pdf">计算实对称矩阵特征值特征向量的幂法_曾莉.pdf</a></li>
<li><a href="/papers/SymMatrix/%E5%88%A9%E7%94%A8%E7%89%B9%E5%BE%81%E7%9F%A9%E9%98%B5%E6%B1%82%E5%AE%9E%E5%AF%B9%E7%A7%B0%E7%9F%A9%E9%98%B5%E7%9A%84%E7%89%B9%E5%BE%81%E5%90%91%E9%87%8F_%E5%AD%9F%E5%AE%AA%E8%90%8C.pdf">利用特征矩阵求实对称矩阵的特征向量_孟宪萌.pdf</a></li>
</ol>
<h3 id="其他特殊矩阵">其他特殊矩阵</h3>
<ol>
<li><a href="https://mp.weixin.qq.com/s/Ci8iJ1YK3-AV8xWbGMJwrw">幂等矩阵、投影矩阵和Cochran定理</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzI3NzE3NDAxMg==&amp;mid=2247490095&amp;idx=1&amp;sn=16bc42b1823fc8067270b2a4428600f0&amp;chksm=eb6b19bcdc1c90aacb507441d5b4e4fb8a72ef1ffb4f2f161c44549aad063f11ccfaef076842&amp;scene=178&amp;cur_album_id=2185022661871960071#rd">Cochran定理</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzI3NzE3NDAxMg==&amp;mid=2247484817&amp;idx=1&amp;sn=74dc04683a2da5b0282be80f0e0505dc&amp;chksm=eb6b0602dc1c8f1447ec134259af88d42f2b67c10a3fde0026d4dbf594fb7955b4420bbbfd1a&amp;cur_album_id=2185022661871960071&amp;scene=190#rd">分块矩阵及其统计学应用</a></li>
</ol>

        
        ]]>
      </description>
    </item>
    
    
    
    <item>
      <title>秦导推荐</title>
      <link>/cn/2022/09/21/qinrecom/</link>
      <pubDate>Wed, 21 Sep 2022 00:00:00 +0000</pubDate>
      <author>Tan Jay</author>
      <guid>/cn/2022/09/21/qinrecom/</guid>
      <description>
        <![CDATA[
        <h2 id="老师手稿">老师手稿</h2>
<ul>
<li><a href="/papers/QinRecom/Qin-1.pdf">统计模拟和实证介绍</a> <a href="/papers/QinRecom/Qin-1-code.R"><code>CODE</code></a></li>
</ul>
<h2 id="写作推荐">写作推荐</h2>
<ul>
<li><a href="/papers/QinRecom/Abstra-1.pdf">范文 1</a></li>
<li><a href="/papers/QinRecom/Abstra-2.pdf">范文 2</a></li>
</ul>
<h2 id="经济类">经济类</h2>
<p>来自<a href="www.must.edu.mo/cn/msb/staff">澳门科技大学老师主页</a>。</p>
<ul>
<li><a href="/papers/QinRecom/Lin-1.pdf"><code>PDF1</code></a></li>
<li><a href="/papers/QinRecom/Lin-2.pdf"><code>PDF2</code></a></li>
<li><a href="/papers/QinRecom/Lin-3.pdf"><code>PDF3</code></a></li>
<li><a href="/papers/QinRecom/Lin-4.pdf"><code>PDF4</code></a></li>
<li><a href="/papers/QinRecom/Lin-5.pdf"><code>PDF5</code></a></li>
<li><a href="/papers/QinRecom/Lin-6.pdf"><code>PDF6</code></a></li>
</ul>

        
        ]]>
      </description>
    </item>
    
    
    
    <item>
      <title>论文英语</title>
      <link>/cn/2022/07/26/paper_skill/</link>
      <pubDate>Tue, 26 Jul 2022 00:00:00 +0000</pubDate>
      <author>Tan Jay</author>
      <guid>/cn/2022/07/26/paper_skill/</guid>
      <description>
        <![CDATA[
        <h2 id="原则">原则</h2>
<ol>
<li>公式简洁</li>
<li>突出亮点（人无你有）</li>
</ol>
<h2 id="摘要">摘要</h2>
<h3 id="提出问题">提出问题</h3>
<ol>
<li>The ** is a ** problem.</li>
<li>It aims to do sth.</li>
<li>Aim to do sth</li>
<li>** has been widely used in many problems, but there are few relevant studies on **.</li>
</ol>
<h3 id="传统方法">传统方法</h3>
<ol>
<li>Traditional methods have difficulty ensuring sth when **.</li>
<li>Since (reason).<br>
It makes the method prone to miss the optimal solution, resulting in **.</li>
<li>**, leading to ** with low accuracy.</li>
<li>**, leading to the failure of sth.</li>
<li>Although, these ** can solve the problems, but ** still cannot meet the requirements.</li>
</ol>
<h3 id="建议方法">建议方法</h3>
<ol>
<li>In this work, ** method based on ** and ** is proposed to solve the problem.</li>
<li>A novel strategy was introduced into ** to improve the capability by v-ing.</li>
<li>A new ** is proposed, which **, then **.</li>
<li>, which is very effective for solving **.</li>
<li>The technologies that have been successfully applied include **, ** and so on.</li>
<li>** is used to solve the problem in complex environment.</li>
<li>owing to its advantage of **, ** shows remarkable performance in solving **.</li>
<li>In this paper, ** is proposed to handle the problems.</li>
<li>The method can alleviate **.</li>
</ol>
<h3 id="数值试验">数值试验</h3>
<ol>
<li>The simulation experimental results in ** show that the new method can ** and its performance is **.</li>
<li>The comparative experiments in these reports verify the effectiveness and reliability of these methods.</li>
<li>The superiority of the proposed method is experimentally verified.</li>
</ol>
<h2 id="行文">行文</h2>
<h3 id="句子">句子</h3>
<ol>
<li>is an indispensable part of</li>
<li>A series of algorithms</li>
<li>the number of nodes v-s</li>
<li>Sth have been proposed to solve this complex multi-constraint optimization problem</li>
<li>such as **, **, and **.</li>
<li>As sth increases and sth becomes adj.</li>
<li>The computational effort increases exponentially</li>
<li>in dealing with such problems</li>
<li>method used in paper</li>
<li>studied by researchers</li>
<li>proposed by sb</li>
<li>introduced by sb</li>
<li>inspired by sth</li>
<li>The research shows that **.</li>
<li>owing to its advantages</li>
<li>To improve sth, sb embeds sth into sth.</li>
<li>effects on</li>
<li>move toward</li>
<li>a hybrid strategy</li>
<li>the information is collected through ** to provide more ** for v-ing sth.</li>
<li>** is constructed</li>
<li>the information can be shared</li>
<li>The rest of the paper is explained as follows:</li>
<li>Section 1 describes **.</li>
<li>a summary is given in Section 5.</li>
</ol>
<h2 id="词藻">词藻</h2>
<h3 id="否定">否定</h3>
<ol>
<li>insufficient</li>
<li>low accuracy</li>
<li>premature</li>
<li>low timeliness</li>
</ol>
<h3 id="肯定">肯定</h3>
<ol>
<li>navel</li>
<li>effective and feasible</li>
<li>successfully</li>
<li>is superior to the other sth.</li>
<li>remarkable</li>
<li>elite</li>
<li>competitive</li>
<li>effectiveness and reliability</li>
<li>computational efficiency</li>
<li>recognition accuracy</li>
<li>promising</li>
</ol>
<h2 id="总结">总结</h2>

        
        ]]>
      </description>
    </item>
    
    
  </channel>
</rss>
